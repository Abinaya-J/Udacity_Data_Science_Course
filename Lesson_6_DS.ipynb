{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson 6 DS.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPIOe3ueblvGBVSCfSggIRw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abinaya-J/Udacity_Intro_to_Data_Science/blob/master/Lesson_6_DS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztyb0ZOn7p_R"
      },
      "source": [
        "#Exploratory Data Analysis\n",
        "\n",
        "import numpy as np\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def entries_histogram(turnstile_weather):\n",
        "    '''\n",
        "    Before we perform any analysis, it might be useful to take a\n",
        "    look at the data we're hoping to analyze. More specifically, let's \n",
        "    examine the hourly entries in our NYC subway data and determine what\n",
        "    distribution the data follows. This data is stored in a dataframe\n",
        "    called turnstile_weather under the ['ENTRIESn_hourly'] column.\n",
        "    \n",
        "    Let's plot two histograms on the same axes to show hourly\n",
        "    entries when raining vs. when not raining. Here's an example on how\n",
        "    to plot histograms with pandas and matplotlib:\n",
        "    turnstile_weather['column_to_graph'].hist()\n",
        "    \n",
        "    Your histogram may look similar to bar graph in the instructor notes below.\n",
        "    \n",
        "    You can read a bit about using matplotlib and pandas to plot histograms here:\n",
        "    http://pandas.pydata.org/pandas-docs/stable/visualization.html#histograms\n",
        "    \n",
        "    You can see the information contained within the turnstile weather data here:\n",
        "    https://s3.amazonaws.com/content.udacity-data.com/courses/ud359/turnstile_data_master_with_weather.csv\n",
        "    '''\n",
        "    \n",
        "    plt.figure()\n",
        "    turnstile_weather[turnstile_weather['rain']==1]['ENTRIESn_hourly'].hist() \n",
        "    turnstile_weather[turnstile_weather['rain']==0]['ENTRIESn_hourly'].hist() \n",
        "    return plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHQdHKA2SZ4Q"
      },
      "source": [
        "#Mann-Whitney U-Test\n",
        "\n",
        "import numpy as np\n",
        "import scipy\n",
        "import scipy.stats\n",
        "import pandas\n",
        "\n",
        "def mann_whitney_plus_means(turnstile_weather):\n",
        "    '''\n",
        "    This function will consume the turnstile_weather dataframe containing\n",
        "    our final turnstile weather data. \n",
        "    \n",
        "    You will want to take the means and run the Mann Whitney U-test on the \n",
        "    ENTRIESn_hourly column in the turnstile_weather dataframe.\n",
        "    \n",
        "    This function should return:\n",
        "        1) the mean of entries with rain\n",
        "        2) the mean of entries without rain\n",
        "        3) the Mann-Whitney U-statistic and p-value comparing the number of entries\n",
        "           with rain and the number of entries without rain\n",
        "    \n",
        "    You should feel free to use scipy's Mann-Whitney implementation, and you \n",
        "    might also find it useful to use numpy's mean function.\n",
        "    \n",
        "    Here are the functions' documentation:\n",
        "    http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html\n",
        "    http://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html\n",
        "    \n",
        "    You can look at the final turnstile weather data at the link below:\n",
        "    https://s3.amazonaws.com/content.udacity-data.com/courses/ud359/turnstile_data_master_with_weather.csv\n",
        "    '''\n",
        "    with_rain = turnstile_weather[turnstile_weather['rain']==1]['ENTRIESn_hourly']\n",
        "    without_rain = turnstile_weather[turnstile_weather['rain']==0]['ENTRIESn_hourly']\n",
        "    with_rain_mean = np.mean(with_rain)\n",
        "    without_rain_mean = np.mean(without_rain)\n",
        "    U,p = scipy.stats.mannwhitneyu(with_rain,without_rain)\n",
        "    \n",
        "    return with_rain_mean, without_rain_mean, U, p # leave this line for the grader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHVgOllWSnXj"
      },
      "source": [
        "#Linear Regression\n",
        "\n",
        "import numpy as np\n",
        "import pandas\n",
        "from ggplot import *\n",
        "\n",
        "\"\"\"\n",
        "In this question, you need to:\n",
        "1) implement the compute_cost() and gradient_descent() procedures\n",
        "2) Select features (in the predictions procedure) and make predictions.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def normalize_features(df):\n",
        "    \"\"\"\n",
        "    Normalize the features in the data set.\n",
        "    \"\"\"\n",
        "    mu = df.mean()\n",
        "    sigma = df.std()\n",
        "    \n",
        "    if (sigma == 0).any():\n",
        "        raise Exception(\"One or more features had the same value for all samples, and thus could \" + \\\n",
        "                         \"not be normalized. Please do not include features with only a single value \" + \\\n",
        "                         \"in your model.\")\n",
        "    df_normalized = (df - df.mean()) / df.std()\n",
        "\n",
        "    return df_normalized, mu, sigma\n",
        "\n",
        "def compute_cost(features, values, theta):\n",
        "    \"\"\"\n",
        "    Compute the cost function given a set of features / values, \n",
        "    and the values for our thetas.\n",
        "    \n",
        "    This can be the same code as the compute_cost function in the lesson #3 exercises,\n",
        "    but feel free to implement your own.\n",
        "    \"\"\"\n",
        "    \n",
        "    m = len(values)\n",
        "    sum_of_square_errors = np.square(np.dot(features, theta) - values).sum()\n",
        "    cost = sum_of_square_errors / (2*m)\n",
        "\n",
        "    return cost\n",
        "\n",
        "def gradient_descent(features, values, theta, alpha, num_iterations):\n",
        "    \"\"\"\n",
        "    Perform gradient descent given a data set with an arbitrary number of features.\n",
        "    \n",
        "    This can be the same gradient descent code as in the lesson #3 exercises,\n",
        "    but feel free to implement your own.\n",
        "    \"\"\"\n",
        "    \n",
        "    m = len(values)\n",
        "    cost_history = []\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        pred_values=np.dot(features,theta)\n",
        "        theta = theta+ (alpha/m * np.dot(values-pred_values,features))\n",
        "        cost=compute_cost(features,values,theta)\n",
        "        cost_history.append(cost)\n",
        "    return theta, pandas.Series(cost_history)\n",
        "\n",
        "def predictions(dataframe):\n",
        "    '''\n",
        "    The NYC turnstile data is stored in a pandas dataframe called weather_turnstile.\n",
        "    Using the information stored in the dataframe, let's predict the ridership of\n",
        "    the NYC subway using linear regression with gradient descent.\n",
        "    \n",
        "    You can download the complete turnstile weather dataframe here:\n",
        "    https://www.dropbox.com/s/meyki2wl9xfa7yk/turnstile_data_master_with_weather.csv    \n",
        "    \n",
        "    Your prediction should have a R^2 value of 0.40 or better.\n",
        "    You need to experiment using various input features contained in the dataframe. \n",
        "    We recommend that you don't use the EXITSn_hourly feature as an input to the \n",
        "    linear model because we cannot use it as a predictor: we cannot use exits \n",
        "    counts as a way to predict entry counts. \n",
        "    \n",
        "    Note: Due to the memory and CPU limitation of our Amazon EC2 instance, we will\n",
        "    give you a random subet (~15%) of the data contained in \n",
        "    turnstile_data_master_with_weather.csv. You are encouraged to experiment with \n",
        "    this computer on your own computer, locally. \n",
        "    \n",
        "    \n",
        "    If you'd like to view a plot of your cost history, uncomment the call to \n",
        "    plot_cost_history below. The slowdown from plotting is significant, so if you \n",
        "    are timing out, the first thing to do is to comment out the plot command again.\n",
        "    \n",
        "    If you receive a \"server has encountered an error\" message, that means you are \n",
        "    hitting the 30-second limit that's placed on running your program. Try using a \n",
        "    smaller number for num_iterations if that's the case.\n",
        "    \n",
        "    If you are using your own algorithm/models, see if you can optimize your code so \n",
        "    that it runs faster.\n",
        "    '''\n",
        "    # Select Features (try different features!)\n",
        "    features = dataframe[['rain', 'precipi', 'Hour', 'meantempi']]\n",
        "    \n",
        "    # Add UNIT to features using dummy variables\n",
        "    dummy_units = pandas.get_dummies(dataframe['UNIT'], prefix='unit')\n",
        "    features = features.join(dummy_units)\n",
        "    \n",
        "    # Values\n",
        "    values = dataframe['ENTRIESn_hourly']\n",
        "    m = len(values)\n",
        "\n",
        "    features, mu, sigma = normalize_features(features)\n",
        "    features['ones'] = np.ones(m) # Add a column of 1s (y intercept)\n",
        "    \n",
        "    # Convert features and values to numpy arrays\n",
        "    features_array = np.array(features)\n",
        "    values_array = np.array(values)\n",
        "\n",
        "    # Set values for alpha, number of iterations.\n",
        "    alpha = 0.1 # please feel free to change this value\n",
        "    num_iterations = 75 # please feel free to change this value\n",
        "\n",
        "    # Initialize theta, perform gradient descent\n",
        "    theta_gradient_descent = np.zeros(len(features.columns))\n",
        "    theta_gradient_descent, cost_history = gradient_descent(features_array, \n",
        "                                                            values_array, \n",
        "                                                            theta_gradient_descent, \n",
        "                                                            alpha, \n",
        "                                                            num_iterations)\n",
        "    \n",
        "    plot = None\n",
        "    # -------------------------------------------------\n",
        "    # Uncomment the next line to see your cost history\n",
        "    # -------------------------------------------------\n",
        "    # plot = plot_cost_history(alpha, cost_history)\n",
        "    # \n",
        "    # Please note, there is a possibility that plotting\n",
        "    # this in addition to your calculation will exceed \n",
        "    # the 30 second limit on the compute servers.\n",
        "    \n",
        "    predictions = np.dot(features_array, theta_gradient_descent)\n",
        "    return predictions, plot\n",
        "\n",
        "\n",
        "def plot_cost_history(alpha, cost_history):\n",
        "   \"\"\"This function is for viewing the plot of your cost history.\n",
        "   You can run it by uncommenting this\n",
        "\n",
        "       plot_cost_history(alpha, cost_history) \n",
        "\n",
        "   call in predictions.\n",
        "   \n",
        "   If you want to run this locally, you should print the return value\n",
        "   from this function.\n",
        "   \"\"\"\n",
        "   cost_df = pandas.DataFrame({\n",
        "      'Cost_History': cost_history,\n",
        "      'Iteration': range(len(cost_history))\n",
        "   })\n",
        "   return ggplot(cost_df, aes('Iteration', 'Cost_History')) + \\\n",
        "      geom_point() + ggtitle('Cost History for alpha = %.3f' % alpha )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFsb9JpuVdtv"
      },
      "source": [
        "#Plotting Residuals\n",
        "import numpy as np\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_residuals(turnstile_weather, predictions):\n",
        "    '''\n",
        "    Using the same methods that we used to plot a histogram of entries\n",
        "    per hour for our data, why don't you make a histogram of the residuals\n",
        "    (that is, the difference between the original hourly entry data and the predicted values).\n",
        "    Try different binwidths for your histogram.\n",
        "\n",
        "    Based on this residual histogram, do you have any insight into how our model\n",
        "    performed?  Reading a bit on this webpage might be useful:\n",
        "\n",
        "    http://www.itl.nist.gov/div898/handbook/pri/section2/pri24.htm\n",
        "    '''\n",
        "    \n",
        "    plt.figure()\n",
        "    (turnstile_weather['ENTRIESn_hourly'] - predictions).hist()\n",
        "    return plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2RYzsTdVebG"
      },
      "source": [
        "#Compute R^2\n",
        "\n",
        "import numpy as np\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "\n",
        "def compute_r_squared(data, predictions):\n",
        "    '''\n",
        "    In exercise 5, we calculated the R^2 value for you. But why don't you try and\n",
        "    and calculate the R^2 value yourself.\n",
        "    \n",
        "    Given a list of original data points, and also a list of predicted data points,\n",
        "    write a function that will compute and return the coefficient of determination (R^2)\n",
        "    for this data.  numpy.mean() and numpy.sum() might both be useful here, but\n",
        "    not necessary.\n",
        "\n",
        "    Documentation about numpy.mean() and numpy.sum() below:\n",
        "    http://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html\n",
        "    http://docs.scipy.org/doc/numpy/reference/generated/numpy.sum.html\n",
        "    '''\n",
        "    \n",
        "    numerator=np.sum(np.square(data-predictions))\n",
        "    denominator=np.sum(np.square(data-np.mean(data)))\n",
        "    r_squared = 1-numerator/denominator\n",
        "    \n",
        "    return r_squared"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}